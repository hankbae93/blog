---
title: "PRD: LocalFirst Agent"
description: "> 클라우드 없이 완전 로컬에서 동작하는 AI 비서. \"클라우드가 더 강력하다\"는 전제를 깨고, 통제권의 가치를 묻는다."
keywords: "PRD, 기획서, 요구사항, MVP, LocalFirst Agent"
date: "2026-01-28"
---

# PRD: LocalFirst Agent

> 클라우드 없이 완전 로컬에서 동작하는 AI 비서. "클라우드가 더 강력하다"는 전제를 깨고, 통제권의 가치를 묻는다.

**문서 정보**
- 작성일: 2026-01-28
- 버전: 1.0
- 상태: Draft
- 트랙: Essence

---

## 1. 개요 (Overview)

### 1.1 문제 정의 (Problem Statement)

- **누가** 겪는 문제인가?
  - 민감한 데이터(개인 일기, 의료 기록, 재무 정보)를 AI에 물어보고 싶지만 클라우드에 보내기 꺼려지는 사용자
  - 비행기, 지하철, 오지에서 오프라인일 때도 AI 비서가 필요한 사람
  - 월 $20 구독료가 부담스럽거나, 내 데이터로 학습되는 게 싫은 사용자
  - Apple Silicon Mac 사용자 (M1/M2/M3/M4) - 강력한 로컬 연산 능력을 가졌지만 활용 못함

- **무엇이** 문제인가?
  - ChatGPT, Claude 등 모든 AI 비서가 클라우드 기반 - 인터넷 없으면 무용지물
  - 민감한 질문을 하려면 내 데이터가 외부 서버로 전송됨
  - 월 $20-30 구독료를 내면서도 데이터 소유권은 사용자에게 없음
  - 로컬 LLM은 있지만 (Ollama, LM Studio), 비개발자에게는 설치/관리가 어려움
  - Apple Silicon의 강력한 Neural Engine이 AI 비서용으로는 거의 활용 안 됨

- **왜** 문제인가?
  - **파괴해야 할 전제:** "클라우드 AI가 로컬 AI보다 항상 더 강력하고 편리하다"
  - **실제 현실:** 클라우드 AI는 "더 강력"할 수 있지만, "더 나은"은 아님. 프라이버시, 오프라인 접근성, 비용, 데이터 통제권을 희생함
  - 사용자들은 80%의 AI 작업을 7B-13B 모델로도 충분히 처리 가능함에도, GPT-4급 모델 비용을 지불
  - "내 데이터는 내 기기에만" 있어야 한다는 기본 권리가 클라우드 시대에 무시됨
  - AI 비서의 진짜 가치는 "항상 옆에 있는 것"인데, 오프라인에서 사라지면 비서가 아님

### 1.2 솔루션 요약 (Solution Summary)

- **핵심 가치 제안**: Apple Silicon Mac에서 클릭 한 번으로 설치하고, 인터넷 없이도 완전히 동작하며, 내 데이터가 절대 기기를 떠나지 않는 AI 비서. 클라우드 AI의 80%를 커버하면서 100%의 프라이버시와 통제권을 제공한다.

### 1.3 성공 지표 (Success Metrics)

| 지표 | 목표 | 측정 방법 |
|------|------|-----------|
| 설치 후 첫 대화까지 시간 | 5분 이내 | 설치 시작부터 첫 응답까지 측정 |
| 주간 활성 사용률 (WAU) | 60% 이상 | 설치 사용자 중 주 1회 이상 사용 비율 |
| 오프라인 사용 비율 | 30% 이상 | 전체 대화 중 오프라인 상태에서 발생한 비율 |
| NPS (Net Promoter Score) | 50 이상 | 분기별 사용자 설문 |
| 월간 이탈률 (Churn) | 15% 미만 | 월 비활성화된 사용자 비율 |

---

## 2. 타겟 사용자 (Target Users)

### 2.1 주요 페르소나

**페르소나 이름: 민지 (Minji)**

- **직업/역할:** 의사, 30대 후반
- **인구통계:** 38세, 서울 거주, MacBook Pro M3 사용
- **기술 수준:** 중급. 기본적인 앱 사용은 능숙하나 터미널 사용은 어려움
- **주요 고충점:**
  - 환자 케이스에 대해 AI에게 물어보고 싶지만, HIPAA/개인정보보호법 위반 우려
  - "이 증상 패턴이 뭘 의미하지?"를 ChatGPT에 물어보면 환자 정보가 OpenAI 서버로 감
  - 병원 내부망에서는 외부 AI 서비스 접근 제한됨
  - Ollama 설치해봤지만 터미널 명령어가 어려워서 포기
- **현재 대안:**
  - 환자 정보 빼고 일반적인 질문만 ChatGPT에 함 (비효율적)
  - 동료에게 물어봄 (시간 오래 걸림)
  - 교과서/논문 검색 (AI 대비 느림)

**페르소나 이름: 준호 (Junho)**

- **직업/역할:** 프리랜서 작가/번역가
- **인구통계:** 32세, 디지털 노마드, MacBook Air M2 사용
- **기술 수준:** 기본. 앱 설치/사용은 가능하나 개발 지식 없음
- **주요 고충점:**
  - 동남아, 유럽 등 인터넷 불안정한 곳에서 자주 일함
  - 비행기에서 12시간 이동 중에 AI 도움으로 글 쓰고 싶음
  - 월 $20 구독료가 프리랜서 수입 대비 부담됨
  - 자신이 쓴 글이 AI 회사 학습 데이터로 쓰일까 봐 불안
- **현재 대안:**
  - 인터넷 되는 곳에서만 AI 사용 (이동 중 생산성 저하)
  - DeepL 같은 오프라인 일부 지원 도구 (기능 제한적)
  - 미리 ChatGPT 답변을 캐시해둠 (비효율적)

**페르소나 이름: 태영 (Taeyoung)**

- **직업/역할:** 스타트업 CEO, 기술 배경 있음
- **인구통계:** 45세, 실리콘밸리 거주, Mac Studio M2 Ultra 사용
- **기술 수준:** 고급. 터미널 사용 가능, 개발 경험 있음
- **주요 고충점:**
  - 회사 기밀 전략, 재무 데이터에 대해 AI 자문받고 싶음
  - 투자자 미팅 전략, M&A 검토 등 민감한 내용은 외부로 절대 못 보냄
  - Ollama를 쓰지만 UI가 불편하고, 팀에게 추천하기엔 진입장벽 높음
  - "설치 한 번 하면 끝"인 깔끔한 솔루션이 없음
- **현재 대안:**
  - Ollama + Open WebUI 자체 구축 (유지보수 귀찮음)
  - 민감하지 않은 작업만 Claude에게 함
  - 결국 많은 고민을 AI 없이 혼자 함

### 2.2 사용자 시나리오

> "민지는 희귀 증후군 환자를 진료했다. 비슷한 케이스의 치료 방향이 궁금했지만, 환자의 구체적 증상과 검사 결과를 ChatGPT에 입력하는 것은 개인정보보호법 위반이다. 결국 교과서와 논문을 뒤져 2시간을 썼다. LocalFirst Agent가 있었다면, 모든 데이터가 자신의 MacBook에서만 처리되니 환자 정보를 포함해 질문할 수 있었고, 10분 만에 유사 사례와 치료 옵션을 얻을 수 있었을 것이다."

> "준호는 발리행 비행기에서 12시간 동안 번역 작업을 해야 했다. 평소에는 Claude에게 어색한 문장을 다듬어 달라고 부탁하지만, 비행기에서는 인터넷이 없다. 결국 원고를 완성하지 못하고 착륙했다. LocalFirst Agent가 있었다면, 오프라인에서도 AI 비서와 함께 작업하며 비행기에서 원고를 완성할 수 있었을 것이다."

> "태영은 경쟁사 인수 제안서를 검토 중이다. AI에게 '이 딜의 리스크가 뭐지?'를 물어보고 싶지만, 인수 금액, 대상 회사명 등 정보가 외부로 새면 큰 문제다. 결국 혼자 분석했고, 놓친 관점이 있었다. LocalFirst Agent가 있었다면, 모든 문서를 로컬에서 안전하게 분석하고 인사이트를 얻을 수 있었을 것이다."

---

## 3. 기능 요구사항 (Functional Requirements)

### 3.1 MVP 필수 기능 (Must Have)

#### F1: One-Click Setup (원클릭 설치)
- **설명:** 기술 지식 없이도 클릭 한 번으로 로컬 AI 비서를 설치하고 시작할 수 있음. Ollama 설치, 모델 다운로드, UI 설정이 모두 자동화됨.
- **사용자 스토리:** As a non-technical user, I want to install a local AI assistant with one click, so that I can start using AI without dealing with terminals or configurations.
- **수용 기준:**
  - [ ] macOS 앱 다운로드 후 드래그 앤 드롭으로 설치
  - [ ] 첫 실행 시 자동으로 mlx-community 모델 다운로드 (7B 기본, 13B 선택)
  - [ ] 설치 진행 상황을 친절한 UI로 표시 ("잠깐만요, AI가 당신의 Mac에 정착 중이에요")
  - [ ] 설치 완료까지 5분 이내 (인터넷 속도에 따라 다름)
  - [ ] 설치 완료 후 바로 대화 가능
  - [ ] 업데이트 자동 알림 및 원클릭 업그레이드

#### F2: Always-Available Chat (항상 가능한 대화)
- **설명:** 인터넷 연결 상태와 무관하게 AI 비서와 대화 가능. 오프라인/온라인 전환이 자연스럽고, 사용자는 차이를 느끼지 않음.
- **사용자 스토리:** As a digital nomad, I want my AI assistant to work everywhere including planes and remote areas, so that I'm not dependent on internet connectivity.
- **수용 기준:**
  - [ ] 인터넷 없어도 모든 대화 기능 동작
  - [ ] 오프라인 상태에서도 응답 품질 저하 없음 (동일 모델 사용)
  - [ ] 메뉴바 아이콘으로 현재 상태 표시 (연결/비연결)
  - [ ] 대화 기록은 로컬에 저장, 앱 재시작해도 유지
  - [ ] 키보드 단축키 (Cmd+Shift+L)로 즉시 호출
  - [ ] 시스템 전역 호출 가능 (어떤 앱에서도 AI 호출)

#### F3: Private by Design (설계부터 프라이버시)
- **설명:** 사용자의 모든 데이터가 절대 기기를 떠나지 않음을 기술적으로 보장. 네트워크 연결 자체를 차단하는 옵션 제공.
- **사용자 스토리:** As a healthcare professional, I want to be certain that patient-related queries never leave my device, so that I can use AI without violating privacy regulations.
- **수용 기준:**
  - [ ] 모든 AI 처리는 100% 로컬 (Apple MLX 또는 llama.cpp 기반)
  - [ ] 앱 자체가 외부 네트워크 연결 안 함 (텔레메트리 없음)
  - [ ] "비행기 모드" 옵션: 시스템 네트워크 권한 자체를 요청 안 함
  - [ ] 대화 기록은 암호화되어 로컬 저장 (AES-256)
  - [ ] "모든 데이터 삭제" 버튼으로 완전 초기화 가능
  - [ ] 앱 설정에서 "이 앱은 인터넷에 절대 연결되지 않습니다" 명시

### 3.2 향후 기능 (Nice to Have)
- **로컬 RAG (Retrieval-Augmented Generation)**: 내 문서를 인덱싱하고, 관련 문서 기반으로 답변
- **음성 대화**: mlx-audio 기반 음성 인식/합성으로 핸즈프리 AI 비서
- **멀티 모델 지원**: 작업에 따라 7B/13B/코딩특화 모델 자동 선택
- **iOS 연동**: Mac에서 처리하고 iPhone에서 결과 확인 (로컬 네트워크)
- **플러그인 시스템**: 캘린더, 이메일 등 로컬 데이터 연동

### 3.3 명시적 제외 (Out of Scope)
- **클라우드 동기화**: 로컬 퍼스트 철학에 반함. 디바이스 간 동기화 제공 안 함
- **클라우드 AI 폴백**: "로컬이 느리면 클라우드로" 같은 타협 안 함
- **사용자 데이터 수집**: 어떤 형태의 텔레메트리도 없음
- **Windows/Linux 지원**: MVP는 Apple Silicon Mac 전용. 추후 확장 고려
- **엔터프라이즈 기능**: 팀 관리, SSO 등 기업용 기능은 Phase 2 이후

---

## 4. 기술 요구사항 (Technical Requirements)

### 4.1 시스템 아키텍처

```
+------------------+     +------------------+     +------------------+
|    User          |     |   LocalFirst     |     |    Apple MLX     |
|    Interface     |<--->|   Agent App      |<--->|    Runtime       |
|    (SwiftUI)     |     |    (Swift)       |     |    (mlx-lm)      |
+------------------+     +------------------+     +------------------+
                                |                        |
                                v                        v
                         +------------------+     +------------------+
                         |    Local DB      |     |    Model Store   |
                         |    (SQLite +     |     |    (~/.localfirst|
                         |     Encryption)  |     |     /models/)    |
                         +------------------+     +------------------+
                                |
                                v
                         +------------------+
                         |    Keychain      |
                         |    (Encryption   |
                         |     Keys)        |
                         +------------------+
```

### 4.2 기술 스택

| 레이어 | 기술 | 선택 이유 |
|--------|------|-----------|
| UI Framework | SwiftUI | 네이티브 macOS, Apple Silicon 최적화, 작은 앱 사이즈 |
| LLM Runtime | MLX (Apple) | Apple Silicon Neural Engine 최적화, 메모리 효율적 |
| 모델 형식 | MLX format | 4-bit 양자화, M1 8GB RAM에서도 7B 모델 구동 |
| 로컬 저장소 | SQLite + SQLCipher | 암호화된 로컬 데이터베이스, 널리 검증됨 |
| 암호화 | AES-256 + Keychain | macOS 네이티브 보안, 하드웨어 키 보호 |
| 배포 | DMG + Notarization | App Store 없이 직접 배포, 빠른 업데이트 |
| 자동 업데이트 | Sparkle | macOS 표준 업데이트 프레임워크 |

### 4.3 외부 의존성

| 의존성 | 용도 | 대안 |
|--------|------|------|
| MLX | LLM 추론 엔진 | llama.cpp (더 범용적이나 최적화 덜 됨) |
| mlx-community 모델 | 사전 양자화된 LLM | HuggingFace 직접 변환 |
| Sparkle | 자동 업데이트 | 수동 업데이트 안내 |
| SQLCipher | DB 암호화 | 자체 암호화 레이어 |

### 4.4 하드웨어 요구사항

| 항목 | 최소 | 권장 |
|------|------|------|
| Mac 종류 | Apple Silicon (M1+) | M2 Pro 이상 |
| RAM | 8GB | 16GB 이상 |
| 저장공간 | 10GB (7B 모델) | 25GB (13B 모델 포함) |
| macOS 버전 | macOS 13 (Ventura) | macOS 14 (Sonoma) |

### 4.5 성능 요구사항

| 지표 | 목표 | 측정 방법 |
|------|------|-----------|
| 첫 토큰 응답 시간 | < 2초 (7B), < 4초 (13B) | 프롬프트 전송부터 첫 토큰까지 |
| 토큰 생성 속도 | > 15 tok/s (M2), > 30 tok/s (M2 Pro) | 연속 생성 시 초당 토큰 수 |
| 앱 시작 시간 | < 3초 | 앱 아이콘 클릭부터 대화 가능까지 |
| 메모리 사용량 | < 6GB (7B 모델) | 활성 대화 중 |
| 배터리 효율 | GPU 파워 15W 미만 | 연속 대화 시 |

---

## 5. 비즈니스 요구사항 (Business Requirements)

### 5.1 수익 모델

**Freemium + One-Time Purchase**

| 플랜 | 가격 | 포함 내용 |
|------|------|-----------|
| Free | $0 | 7B 모델 무제한, 기본 대화 기능, 대화 기록 저장 |
| Pro | $49 (일회성) | 13B 모델, 로컬 RAG, 음성 대화, 우선 업데이트 |
| Lifetime | $99 (일회성) | Pro 전체 + 모든 미래 업데이트 영구 무료, 얼리어답터 배지 |

**수익 모델 철학**
- 구독 모델 거부: "클라우드 구독에서 벗어나자"는 메시지와 일관성
- 일회성 구매: 로컬 소프트웨어의 전통적 모델로 회귀
- Freemium으로 바이럴: 무료 버전만으로도 충분히 유용하게

**수익 목표**
- Y1 목표: 5,000 유료 구매, $300k 매출
- Y2 목표: 20,000 유료 구매, $1.2M 누적 매출

### 5.2 시장 분석

**TAM (Total Addressable Market)**
- 전 세계 Mac 사용자: 약 1억 명
- AI 비서 사용 경험 있는 Mac 사용자: 약 3,000만 명
- TAM: $3B (연간)

**SAM (Serviceable Addressable Market)**
- Apple Silicon Mac 사용자: 약 4,000만 명
- 그 중 프라이버시/오프라인 중시하는 사용자: 약 20% = 800만 명
- SAM: $800M

**SOM (Serviceable Obtainable Market)**
- 초기 2년 내 확보 가능 (얼리어답터 + 바이럴): 25,000명
- SOM: $2.5M (Lifetime $99 기준)

**경쟁 환경**
| 경쟁사 | 강점 | 약점 | 우리 차별점 |
|--------|------|------|-------------|
| ChatGPT | 최강 모델 성능 | 클라우드 의존, 구독료 | 완전 로컬, 일회성 구매 |
| Claude | 안전성, 긴 컨텍스트 | 클라우드 의존, 구독료 | 프라이버시 보장 |
| Ollama | 무료, 오픈소스 | CLI 기반, 비개발자 어려움 | 원클릭 설치, GUI |
| LM Studio | GUI 제공 | Electron 기반, 무거움 | 네이티브, 가벼움 |
| Moltbot | 로컬 AI 비서 | 기능 제한적 | Apple Silicon 최적화, 깊은 통합 |

### 5.3 Go-to-Market 전략

**Phase 1: 프라이버시 우선 커뮤니티 공략 (Week 1-4)**
- Product Hunt 런칭: "클라우드 AI에 지친 당신을 위한" 포지셔닝
- Hacker News: "Show HN: Local AI that never phones home"
- r/privacy, r/degoogle, r/LocalLLaMA 서브레딧 타겟
- Moltbot의 460 PH votes를 벤치마크로, 1,000 votes 목표

**Phase 2: Apple 에코시스템 타겟 (Week 5-12)**
- MacStories, 9to5Mac 등 Apple 전문 미디어 리뷰
- "Apple Silicon의 숨겨진 힘" 블로그 시리즈
- r/apple, r/macapps 커뮤니티
- YouTube: "맥북에서 ChatGPT 없이 AI 쓰는 법" 튜토리얼

**Phase 3: 직업군 타겟 마케팅 (Week 13-24)**
- 의료 전문가: HIPAA 준수 AI 어시스턴트 포지셔닝
- 변호사: 클라이언트 기밀 유지 강조
- 작가/저널리스트: 취재 자료 프라이버시
- 기업 임원: 비즈니스 기밀 안전성

---

## 6. 마일스톤 (Milestones)

### Phase 1: MVP (Week 1-3)

**Week 1: 핵심 인프라**
- [ ] MLX 런타임 통합 및 7B 모델 구동 테스트
- [ ] SwiftUI 기반 채팅 인터페이스 구현
- [ ] SQLite + 암호화 레이어 설정
- [ ] 대화 기록 저장/불러오기

**Week 2: 사용자 경험**
- [ ] One-Click 설치 플로우 구현 (모델 다운로드 포함)
- [ ] 메뉴바 앱 형태로 구현 (항상 접근 가능)
- [ ] 키보드 단축키 (Cmd+Shift+L) 전역 호출
- [ ] 첫 사용자 온보딩 화면

**Week 3: 안정화**
- [ ] 에러 핸들링 (모델 로드 실패, 메모리 부족 등)
- [ ] 설정 화면 (모델 선택, 단축키 커스텀)
- [ ] 자동 업데이트 (Sparkle) 통합
- [ ] 내부 테스트 및 버그 수정

**MVP 완료 기준:**
- Apple Silicon Mac에서 클릭 한 번으로 설치
- 오프라인에서 7B 모델과 대화 가능
- 본인 포함 5명 일주일 사용 테스트 완료

### Phase 2: Public Launch (Week 4-6)

**Week 4: 런칭 준비**
- [ ] 랜딩 페이지 제작 (localfirst.ai 도메인)
- [ ] Product Hunt 런칭 자료 준비
- [ ] 사용 설명서/FAQ 작성
- [ ] 10명 베타 테스터 확보 및 피드백 수집

**Week 5: 공개 런칭**
- [ ] Product Hunt 런칭
- [ ] Hacker News "Show HN" 게시
- [ ] r/LocalLLaMA, r/privacy 커뮤니티 공유
- [ ] 초기 피드백 대응 및 핫픽스

**Week 6: 안정화**
- [ ] 사용자 피드백 기반 UX 개선
- [ ] 성능 최적화 (토큰 생성 속도)
- [ ] 크래시 리포트 분석 및 수정
- [ ] 13B 모델 지원 추가

**Launch 완료 기준:**
- Product Hunt 500+ votes
- 1,000 다운로드
- 치명적 버그 0건

### Phase 3: Growth (Week 7-12)

**Week 7-8: Pro 버전**
- [ ] 결제 시스템 통합 (Gumroad 또는 Paddle)
- [ ] Pro 기능: 13B 모델, 로컬 RAG 기본
- [ ] 라이선스 검증 시스템 (오프라인 지원)

**Week 9-10: 로컬 RAG**
- [ ] 로컬 문서 인덱싱 (PDF, TXT, MD)
- [ ] 벡터 DB (로컬) 통합
- [ ] "내 문서 기반 답변" 기능

**Week 11-12: 음성**
- [ ] mlx-audio 통합
- [ ] 음성 입력 (STT)
- [ ] 음성 출력 (TTS) - 옵션

**Growth 완료 기준:**
- 5,000 설치
- 500 유료 전환
- WAU 60% 이상

---

## 7. 리스크 및 의존성 (Risks & Dependencies)

| 리스크 | 영향도 | 발생 가능성 | 대응 방안 |
|--------|--------|-------------|-----------|
| Apple이 MLX 지원 중단 | 치명적 | 낮음 | llama.cpp로 폴백 준비, Metal API 직접 사용 |
| 7B 모델 성능이 기대에 미달 | 높음 | 중간 | 13B 기본 옵션 검토, 특화 모델(코딩/글쓰기) 제공 |
| 경쟁사가 로컬 AI 기능 추가 (Apple, Ollama UI) | 높음 | 높음 | UX 차별화, 원클릭 경험에 집중, 커뮤니티 락인 |
| 모델 용량으로 인한 설치 이탈 | 중간 | 중간 | 스트리밍 다운로드, "커피 한 잔 시간" 프레이밍 |
| App Store 규정 문제 (직접 배포 시) | 낮음 | 중간 | Notarization 철저히, 필요시 App Store 버전 별도 |
| 수익 모델 실패 (무료만 사용) | 높음 | 중간 | Pro 기능 가치 명확히, 얼리어답터 할인으로 전환 유도 |

**핵심 의존성:**
1. **MLX 프레임워크**: Apple이 2023년 말 공개, 활발히 개발 중. 안정성은 검증됨
2. **mlx-community 모델**: HuggingFace에서 커뮤니티가 MLX 형식으로 변환한 모델들
3. **Apple Silicon 보급**: M1 출시 후 3년, 대부분의 Mac이 Apple Silicon으로 전환됨
4. **프라이버시 인식 증가**: AI 시대에 데이터 통제권 관심 급증 - 시장 타이밍 적절

---

## 부록: Essence Track 관점

### 파괴하는 전제
> "클라우드 AI가 로컬 AI보다 항상 더 강력하고 편리하다"

빅테크는 클라우드가 "더 좋다"고 설득한다. 더 큰 모델, 더 빠른 응답, 더 쉬운 접근. 하지만 "더 좋다"의 기준이 그들 것이다. 사용자 관점에서 "더 좋다"는 것은:
- 내 데이터가 안전한 것
- 인터넷 없이도 작동하는 것
- 월 $20를 내지 않아도 되는 것
- 내 기기에서 내가 통제하는 것

LocalFirst Agent는 "80%의 성능으로 100%의 통제권"이라는 새로운 기준을 제시한다.

### 방치된 이유
- **빅테크의 수익 모델**: OpenAI, Google, Microsoft 모두 클라우드 API/구독이 핵심 수익원. 로컬 AI를 밀어줄 이유가 없음
- **오픈소스 커뮤니티의 한계**: Ollama, llama.cpp는 뛰어나지만 개발자 타겟. "일반 사용자를 위한 앱"은 수익성 없어서 아무도 안 만듦
- **Apple의 신중함**: MLX를 만들었지만 직접 "AI 비서 앱"까지 내놓지는 않음 (OpenAI와의 관계 고려?)
- **인식의 시차**: "로컬 AI가 이제 쓸만해졌다"는 사실을 아직 대부분의 사용자가 모름

### 비합리적 행동의 증거
- 의사가 환자 케이스를 ChatGPT에 "정보 빼고" 물어봄 - 비효율적이지만 프라이버시 걱정에 어쩔 수 없음
- 작가가 자신의 글이 AI 학습에 쓰일까 걱정하면서도 ChatGPT로 글 다듬음
- 월 $20를 내면서 "내 데이터는 어디로 가지?"를 궁금해하지만 대안이 없어서 계속 사용
- 비행기에서 12시간 동안 AI 없이 버팀 - "인터넷 없으면 안 되니까 당연히"라고 체념
- Ollama를 설치하다 터미널에서 막혀 포기 - "나는 개발자가 아니니까"라고 자책

### 진정성 요구사항
이 제품은 반드시 **"클라우드 AI에 데이터 보내기 꺼려진 경험이 있는 사람"**이 만들어야 한다:
- 민감한 질문을 ChatGPT 입력창에 치다가 지운 경험
- 비행기에서 "아 이거 Claude한테 물어보면 되는데..." 하며 답답했던 경험
- Ollama 설치는 성공했지만 "이걸 가족에게 추천하긴 어렵겠다"고 느낀 경험
- 월 $20 구독을 취소하고 싶지만 대안이 없어 유지하는 경험

**권장 사항**: ChatGPT/Claude에 입력하지 못하고 삭제한 프롬프트가 3개 이상 있어야 함. 그 억눌린 질문들이 이 제품의 진짜 사용 사례가 된다.

---

## 부록: 관련 배경 자료

### 시장 신호
- **Moltbot** (Product Hunt 460 votes): 로컬 AI 비서에 대한 수요 검증. "privacy-first"가 핵심 셀링 포인트
- **mlx-audio** (GitHub 5.4k stars): Apple Silicon에서 오디오 처리. 로컬 AI 생태계 성장 증거
- **Ollama 성장**: GitHub 100k+ stars, 로컬 LLM 실행이 이제 "가능하다"는 인식 확산
- **Apple Intelligence**: Apple도 "on-device AI"를 강조, 시장 교육 효과

### 기술적 타이밍
- MLX (2023.12 공개): Apple Silicon에 최적화된 ML 프레임워크, 활발히 업데이트 중
- 4-bit 양자화: 7B 모델이 6GB RAM에서 구동 가능해짐
- M1 Mac 보급 3년차: 대부분의 Mac 사용자가 Apple Silicon 소유

### 프라이버시 담론
- EU AI Act: AI 시스템의 투명성/프라이버시 요구 강화
- 기업 데이터 유출 우려: Samsung 직원 ChatGPT 기밀 유출 사건 후 많은 기업이 AI 사용 제한
- "데이터 주권" 논의: 내 데이터는 내가 통제해야 한다는 인식 확산

### 경쟁 제품 분석
- **Moltbot**: 먼저 출시했지만 기능 제한적. "더 나은 Moltbot"이 기회
- **LM Studio**: Electron 기반으로 무겁고, Apple Silicon 최적화 부족
- **Ollama**: 개발자에겐 최고지만, 일반 사용자 진입장벽 높음
- **Jan.ai**: 유망하지만 아직 초기 단계, 안정성 부족

---

*Generated by PRD Agent - Essence Track*
*2026-01-28*
